{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6261877,"sourceType":"datasetVersion","datasetId":3599110}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-01T11:05:19.859396Z","iopub.execute_input":"2024-08-01T11:05:19.859777Z","iopub.status.idle":"2024-08-01T11:06:07.330287Z","shell.execute_reply.started":"2024-08-01T11:05:19.859750Z","shell.execute_reply":"2024-08-01T11:06:07.329324Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.applications import ResNet50\n\n# MobileNet was designed to work on 224 x 224 pixel input images sizes\nimg_rows, img_cols = 224, 224\n\n# Re-loads the MobileNet model without the top or FC layers\nResNet50 = ResNet50(weights = 'imagenet',\n                 include_top = False,\n                 input_shape = (img_rows, img_cols, 3))\n\n\n# # Layers are set to trainable as True by default\n# for layer in Xception.layers:\n#     layer.trainable = True\n\n# # Let's print our layers\n# for (i,layer) in enumerate(Xception.layers):\n#     print(str(i) + \" \"+ layer.__class__.__name__, layer.trainable)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T11:07:21.408437Z","iopub.execute_input":"2024-08-01T11:07:21.409269Z","iopub.status.idle":"2024-08-01T11:07:36.294610Z","shell.execute_reply.started":"2024-08-01T11:07:21.409237Z","shell.execute_reply":"2024-08-01T11:07:36.293771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def addTopModelXception(bottom_model, num_classes):\n    \"\"\"creates the top or head of the model that will be\n    placed ontop of the bottom layers\"\"\"\n\n    top_model = bottom_model.output\n    top_model = GlobalAveragePooling2D()(top_model)\n    top_model = Dense(1024,activation='relu')(top_model)\n    top_model = Dense(1024,activation='relu')(top_model)\n    top_model = Dense(512,activation='relu')(top_model)\n    top_model = Dense(num_classes,activation='softmax')(top_model)\n    return top_model","metadata":{"execution":{"iopub.status.busy":"2024-08-01T11:07:53.301271Z","iopub.execute_input":"2024-08-01T11:07:53.302499Z","iopub.status.idle":"2024-08-01T11:07:53.308992Z","shell.execute_reply.started":"2024-08-01T11:07:53.302460Z","shell.execute_reply":"2024-08-01T11:07:53.307913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\nfrom keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\nfrom tensorflow.keras.layers import BatchNormalization\nfrom keras.models import Model\n\n# Set our class number to 3 (Young, Middle, Old)\nnum_classes = 2\n\nFC_Head = addTopModelXception(ResNet50, num_classes)\n\nmodel = Model(inputs = ResNet50.input, outputs = FC_Head)\n\nprint(model.summary())","metadata":{"execution":{"iopub.status.busy":"2024-08-01T11:08:37.479194Z","iopub.execute_input":"2024-08-01T11:08:37.479914Z","iopub.status.idle":"2024-08-01T11:08:37.973847Z","shell.execute_reply.started":"2024-08-01T11:08:37.479882Z","shell.execute_reply":"2024-08-01T11:08:37.973004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_data_dir = '/kaggle/input/dogs-vs-cats/dataset/train'\nvalidation_data_dir = '/kaggle/input/dogs-vs-cats/dataset/validation'\n\n# Let's use some data augmentaiton\ntrain_datagen = ImageDataGenerator(\n      rescale=1./255,\n      rotation_range=10,\n      width_shift_range=0.1,\n      height_shift_range=0.1,\n      horizontal_flip=True,\n      fill_mode='nearest')\n\nvalidation_datagen = ImageDataGenerator(rescale=1./255)\n\n# set our batch size (typically on most mid tier systems we'll use 16-32)\nbatch_size =16\n\ntrain_generator = train_datagen.flow_from_directory(\n        train_data_dir,\n        target_size=(img_rows, img_cols),\n        batch_size=batch_size,\n        class_mode='categorical')\n\nvalidation_generator = validation_datagen.flow_from_directory(\n        validation_data_dir,\n        target_size=(img_rows, img_cols),\n        batch_size=batch_size,\n        class_mode='categorical')","metadata":{"execution":{"iopub.status.busy":"2024-08-01T11:09:35.194058Z","iopub.execute_input":"2024-08-01T11:09:35.194389Z","iopub.status.idle":"2024-08-01T11:09:40.168186Z","shell.execute_reply.started":"2024-08-01T11:09:35.194364Z","shell.execute_reply":"2024-08-01T11:09:40.167448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from tensorflow.keras.optimizers import RMSprop\n# from tensorflow.keras.optimizers.legacy import RMSprop\n\n# We use a very small learning rate\n# model.compile(loss = 'categorical_crossentropy',\n#               optimizer = 'adam',\n#               metrics = ['accuracy'])\n\nfrom tensorflow import keras\nfrom keras import optimizers\n# optimizer=keras.optimizers.RMSprop(learning_rate=0.01)\n\n# We use a very small learning rate\nmodel.compile(loss = 'categorical_crossentropy',\n              optimizer = keras.optimizers.RMSprop(learning_rate=0.01),\n              metrics = ['accuracy'])\n\n# Enter the number of training and validation samples here\nnb_train_samples = 20000\nnb_validation_samples = 5000\n\n# We only train 5 EPOCHS\nepochs = 5\nbatch_size = 16\n\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch = nb_train_samples // batch_size,\n    epochs = epochs,\n    validation_data = validation_generator,\n    validation_steps = nb_validation_samples // batch_size)\nmodel.save(\"cat_vs_dog.keras\")","metadata":{"execution":{"iopub.status.busy":"2024-08-01T11:18:22.777661Z","iopub.execute_input":"2024-08-01T11:18:22.778275Z","iopub.status.idle":"2024-08-01T11:36:56.454823Z","shell.execute_reply.started":"2024-08-01T11:18:22.778244Z","shell.execute_reply":"2024-08-01T11:36:56.453733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n# Plot training & validation accuracy values\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-01T11:37:18.166516Z","iopub.execute_input":"2024-08-01T11:37:18.167356Z","iopub.status.idle":"2024-08-01T11:37:18.759624Z","shell.execute_reply.started":"2024-08-01T11:37:18.167321Z","shell.execute_reply":"2024-08-01T11:37:18.758701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n# Plot training & validation accuracy values\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-01T11:37:51.750196Z","iopub.execute_input":"2024-08-01T11:37:51.750839Z","iopub.status.idle":"2024-08-01T11:37:52.188102Z","shell.execute_reply.started":"2024-08-01T11:37:51.750808Z","shell.execute_reply":"2024-08-01T11:37:52.187206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport sklearn\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport numpy as np\n\n# We need to recreate our validation generator with shuffle = false\nvalidation_generator = validation_datagen.flow_from_directory(\n        validation_data_dir,\n        target_size=(img_rows, img_cols),\n        batch_size=batch_size,\n        class_mode='categorical',\n        shuffle=False)\n\nclass_labels = validation_generator.class_indices\nclass_labels = {v: k for k, v in class_labels.items()}\nclasses = list(class_labels.values())\n\nnb_train_samples = 20000\nnb_validation_samples = 5000\n\n#Confution Matrix and Classification Report\nY_pred = model.predict(validation_generator, nb_validation_samples // batch_size+1)\ny_pred = np.argmax(Y_pred, axis=1)\n\nprint('Confusion Matrix')\nprint(confusion_matrix(validation_generator.classes, y_pred))\nprint('Classification Report')\ntarget_names = list(class_labels.values())\nprint(classification_report(validation_generator.classes, y_pred, target_names=target_names))\n\nplt.figure(figsize=(8,8))\ncnf_matrix = confusion_matrix(validation_generator.classes, y_pred)\n\nplt.imshow(cnf_matrix, interpolation='nearest')\nplt.colorbar()\ntick_marks = np.arange(len(classes))\n_ = plt.xticks(tick_marks, classes, rotation=90)\n_ = plt.yticks(tick_marks, classes)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T11:38:05.959288Z","iopub.execute_input":"2024-08-01T11:38:05.960007Z","iopub.status.idle":"2024-08-01T11:38:27.962659Z","shell.execute_reply.started":"2024-08-01T11:38:05.959969Z","shell.execute_reply":"2024-08-01T11:38:27.961667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# epoch=5\nimport numpy as np\nimport cv2\nfrom keras.preprocessing import image\nfrom keras.models import load_model\nmodel= load_model('cat_vs_dog.keras')\ndef predict_one_image(img, model):\n  img = cv2.resize(img, (224, 224), interpolation = cv2.INTER_CUBIC)\n  img = np.reshape(img, (1, 224, 224, 3))\n  img = img/255.\n  pred = model.predict(img)\n  class_num = np.argmax(pred)\n  return class_num, np.max(pred)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T11:39:09.800357Z","iopub.execute_input":"2024-08-01T11:39:09.800738Z","iopub.status.idle":"2024-08-01T11:39:11.696494Z","shell.execute_reply.started":"2024-08-01T11:39:09.800709Z","shell.execute_reply":"2024-08-01T11:39:11.695469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# epoch =5\nimport cv2\nimport os\nfrom matplotlib import pyplot as plt\n# datas=os.listdir(\"/kaggle/input/dogs-vs-cats/dataset/test\")\n# test_img = cv2.imread('/kaggle/input/dogs-vs-cats/dataset/test/cats/cat (4752).jpg')\ntest_img = cv2.imread('/kaggle/input/dogs-vs-cats/dataset/test/cats/cat (5824).jpg')\n# test_img = cv2.imread('/kaggle/input/dogs-vs-cats/dataset/test/dogs/dog (211).jpg')\n\npred, probability = predict_one_image(test_img,model)\nprint(probability)\n\nif probability > 0.7:\n    print('%s %d%%' % (datas[pred], round(probability, 2) * 100))\n    _, ax = plt.subplots(1)\n    plt.imshow(test_img)\n    # Turn off tick labels\n    ax.set_yticklabels([])\n    ax.set_xticklabels([])\n    plt.grid('off')\n    plt.show()\nelse:\n    print(\"This is not a dog\" )\n#     print('%s %d%%' % (datas[pred], round(probability, 2) * 100))\n    plt.imshow(test_img)\n\n\n# result, probability = predict_one_image(test_img,model)\n# print(probability)\n# print(result)\n\n# if result == 1:\n#   print(\"This is cat\")\n# else:\n#   print(\"this is dog\")\n#   # reading the image\n# # testImage = img.imread(image_path)\n\n# # displaying the modified image\n# plt.imshow(test_img)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-01T11:57:26.602296Z","iopub.execute_input":"2024-08-01T11:57:26.603282Z","iopub.status.idle":"2024-08-01T11:57:27.087869Z","shell.execute_reply.started":"2024-08-01T11:57:26.603248Z","shell.execute_reply":"2024-08-01T11:57:27.086930Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}